from bs4 import BeautifulSoup
import requests
import csv

nom_productos = []
precios = []
lista_enlaces=[]

# Bucle para iterar sobre todas las páginas
for page_number in range(1, 6):  # Cambia el rango según el número total de páginas
    url = f"https://www.asia-bsas.com.ar/productos/?page={page_number}"
    pedido_obtenido = requests.get(url)
    html_obtenido = pedido_obtenido.text

    soup = BeautifulSoup(html_obtenido, "html.parser")
    divs = soup.find_all("div", class_="item-info-container")

    for div in divs:
        producto = div.find(class_="js-item-name item-name").get_text(strip=True)
        precio = div.find(class_="js-price-display item-price h6").get_text(strip=True)
        enlace = div.find("a", class_="js-item-name item-name")["href"]


        nom_productos.append(producto)
        precios.append(precio)
        lista_enlaces.append(enlace)

# Insertar encabezados

    
datos = {}
for producto, precio, enlace in zip(nom_productos, precios, lista_enlaces):
    datos[producto] = {"Precio": precio, "Enlace del producto": enlace}


# Escribir el diccionario en un archivo CSV
with open("pagina_asia_bsas.csv", "w", newline="") as f:
    w = csv.writer(f)
    
    # Escribir encabezados
    w.writerow(["Producto", "Precio", "Enlace del producto"])
    
    # Escribir datos
    for producto, valores in datos.items():
        w.writerow([producto,"\t",valores["Precio"],"\t",valores["Enlace del producto"]])
