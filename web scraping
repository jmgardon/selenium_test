from bs4 import BeautifulSoup
import requests
import csv

nam_products = []
prices = []
list_link=[]
list_stocks = []

# Bucle para iterar sobre todas las páginas
for page_number in range(1, 6):  # Cambia el rango según el número total de páginas
    url = f"https://www.asia-bsas.com.ar/productos/?page={page_number}"
    order_obtained = requests.get(url)
    html_obtained = order_obtained.text

    soup = BeautifulSoup(html_obtained, "html.parser")
    divs = soup.find_all("div", class_="js-item-product item m-top-none-xs")

    for div in divs:
        product = div.find(class_="js-item-name item-name").get_text(strip=True)
        price = div.find(class_="js-price-display item-price h6").get_text(strip=True)
        link = div.find("a", class_="js-item-name item-name")["href"]
        stock = div.find(class_="item-actions m-top-half")

        nam_products.append(product)
        prices.append(price)
        list_link.append(link)
        if stock != None:
            list_stocks.append("Hay stock")
        else:
            list_stocks.append("NO hay stock")



    
data = {}
for product, price, link, auxstock in zip(nam_products, prices, list_link,list_stocks):
    data[product] = {"Precio": price, "Enlace del producto": link, "disponibilidad de stock":auxstock}
    print(product,"-->","-",price,"-",link,"-",auxstock)
    print()





# Escribir el diccionario en un archivo CSV
"""with open("pagina_asia_bsas.csv", "w", newline="") as f:
    w = csv.writer(f)
    
    # Escribir encabezados
    w.writerow(["Producto", "Precio", "Enlace del producto"])
    
    # Escribir datos
    for product, valores in data.items():
        w.writerow([product,"-",valores["Precio"],"-",valores["Enlace del producto"],"-",valores["disponibilidad de stock"]])"""
